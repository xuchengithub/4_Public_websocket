{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__' (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://192.168.3.3:8000/ (Press CTRL+C to quit)\n",
      "192.168.3.3 - - [25/Jul/2020 23:07:47] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.3.3 - - [25/Jul/2020 23:07:47] \"\u001b[37mGET /video_feed HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    }
   ],
   "source": [
    "# %load webstreaming.py\n",
    "# import the necessary packages\n",
    "\n",
    "# import the necessary packages\n",
    "from pyimagesearch.motion_detection.SingleMotionDetector import * \n",
    "from imutils.video import VideoStream# 将允许我们访问我们的Raspberry Pi 相机模块或 USB网络摄像头.\n",
    "from flask import Response#第4到6行处理导入我们需要的Flask包——我们将使用这些包呈现我们的index.html模板，并将其提供给客户端\n",
    "from flask import Flask\n",
    "from flask import render_template\n",
    "import threading#第7行导入threading库，确保我们可以支持并发 (比如，同时使用多个客户端、网络浏览器和选项卡)。\n",
    "import argparse\n",
    "import datetime\n",
    "import imutils\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "# initialize the output frame and a lock used to ensure thread-safe\n",
    "# exchanges of the output frames (useful when multiple browsers/tabs\n",
    "# are viewing the stream)\n",
    "outputFrame = None#这将是将提供给客户端的帧(投递运动检测)。\n",
    "lock = threading.Lock()#它将在更新ouputFrame时被用来确保线程安全行为(即确保某个帧在更新时不被任何线程尝试读取）。\n",
    "\n",
    "# initialize a flask object\n",
    "app = Flask(__name__)#初始化我们的Flask  app本身，\n",
    "\n",
    "# initialize the video stream and allow the camera sensor to\n",
    "# warmup\n",
    "#vs = VideoStream(usePiCamera=1).start()#行访问我们的视频流:\n",
    "vs = VideoStream(src=0).start()#如果您正在使用一个USB网络摄像头, 您可以保持代码不变。\n",
    "time.sleep(2.0)#否则,如果您正在使用一个RPi相机模块，那您应该取消掉第25行的注释，并将第26行注释掉。 \n",
    "\n",
    "@app.route(\"/\")#下一个函数index将会渲染我们的index.html模板并提供输出视频流:\n",
    "#装饰器其实就是在一个函数内部定义另外一个函数,然后返回一个新的函数,即动态的给一个对象添加额外的职责\n",
    "#\n",
    "def index():#这个函数非常简单—它所做的就是在我们的HTML文件中调用Flask render_template。\n",
    "    # return the rendered template\n",
    "    return render_template(\"index.html\")\n",
    "#我们的下一个函数的功能是:#对我们视频流中的帧进行循环#应用运动检测#在outputFrame上绘制任何结果#而且，这个函数必须以线程安全的方式来执行所有这些操作，以确保支持并发。\n",
    "def detect_motion(frameCount):#我们的detection_motion函数接受单个参数frameCount，它是在SingleMotionDetector类中构建我们的背景bg所需的最小帧数:\n",
    "    # grab global references to the video stream, output frame, and#如果我们没有至少frameCount帧，我们将会继续计算累计加权平均值\n",
    "    # lock variables#一旦frameCount达到了，我们将执行背景去除\n",
    "    global vs, outputFrame, lock#vs: 我们实例化的VideoStream对象,outputFrame: 将提供给客户端的输出帧,lock: 在更新outputFrame之前我们必须获得的线程锁\n",
    "    # initialize the motion detector and the total number of frames\n",
    "    # read thus far\n",
    "    md = SingleMotionDetector(accumWeight=0.1)#使用一个accumWeight=0.1值来初始化我们的SingleMotionDetector 类，这意味着在计算加权平均值时，bg值的权重会更高。\n",
    "    total = 0#初始化到目前为止读取的帧的total数——我们需要确保已经读取了足够多的帧来构建我们的背景模型。\n",
    "# loop over frames from the video stream\n",
    "    while True:\n",
    "        # read the next frame from the video stream, resize it,\n",
    "        # convert the frame to grayscale, and blur it\n",
    "        frame = vs.read()\n",
    "        frame = imutils.resize(frame, width=400)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        gray = cv2.GaussianBlur(gray, (7, 7), 0)\n",
    "        # grab the current timestamp and draw it on the frame\n",
    "        timestamp = datetime.datetime.now()#们获取当前时间戳并将其绘制在frame上(第54-57行)。\n",
    "        cv2.putText(frame, timestamp.strftime(\n",
    "\t\t\t\"%A %d %B %Y %I:%M:%S%p\"), (10, frame.shape[0] - 10),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.35, (0, 0, 255), 1)\n",
    "        # if the total number of frames has reached a sufficient\n",
    "        # number to construct a reasonable background model, then\n",
    "        # continue to process the frame\n",
    "        if total > frameCount:#我们确保我们至少读取了frameCount帧来构建我们的背景去除模型。\n",
    "            # detect motion in the image\n",
    "            motion = md.detect(gray)#应用我们运动检测器的.detect运动，它将返回单个变量motion。\n",
    "            # check to see if motion was found in the frame\n",
    "            if motion is not None:\n",
    "                # unpack the tuple and draw the box surrounding the\n",
    "                # \"motion area\" on the output frame\n",
    "                (thresh, (minX, minY, maxX, maxY)) = motion\n",
    "                cv2.rectangle(frame, (minX, minY), (maxX, maxY),\n",
    "                              (0, 0, 255), 2)\n",
    "\t\t\n",
    "        # update the background model and increment(增加) the total number\n",
    "        # of frames read thus far\n",
    "        md.update(gray)\n",
    "        total += 1\n",
    "        # acquire the lock, set the output frame, and release the\n",
    "        # lock\n",
    "        with lock:#第81行获得支持线程并发所需的lock，而第82行设置outputFrame。\n",
    "            outputFrame = frame.copy()#我们需要获取锁，以确保我们在试图更新outputFrame变量时客户机不会意外读取它。\n",
    "            \n",
    "def generate():#是一个Python生成器，用于将我们的outputFrame编码为JPEG数据——现在让我们来看看它:\n",
    "        # grab global references to the output frame and lock variables\n",
    "        global outputFrame, lock#获取对outputFrame和lock的全局引用，类似于detect_motion函数。\n",
    "        # loop over frames from the output stream\n",
    "        while True:#获取对outputFrame和lock的全局引用，类似于detect_motion函数。\n",
    "            # wait until the lock is acquired\n",
    "            with lock:\n",
    "                # check if the output frame is available, otherwise skip\n",
    "                # the iteration of the loop\n",
    "                if outputFrame is None:\n",
    "                    continue\n",
    "                # encode the frame in JPEG format\n",
    "                (flag, encodedImage) = cv2.imencode(\".jpg\", outputFrame)\n",
    "                # ensure the frame was successfully encoded\n",
    "                if not flag:\n",
    "                    continue\n",
    "            # yield the output frame in the byte format\n",
    "            yield(b'--frame\\r\\n' b'Content-Type: image/jpeg\\r\\n\\r\\n' + \n",
    "                  bytearray(encodedImage) + b'\\r\\n')\n",
    "#函数video_feed会调用我们的generate函数:\n",
    "            \n",
    "######################这个app.route签名告诉Flask这个函数是一个URL端点，数据是从http://your_ip_address/video_feed提供的。\n",
    "            #video_feed的输出是实时运动检测输出，通过generate函数编码为一个字节数组。您的网络浏览器非常聪明，可以将这个字节数组作为一个实时输出显示在您的浏览器中。\n",
    "@app.route(\"/video_feed\")\n",
    "def video_feed():\n",
    "        # return the response generated along with the specific media\n",
    "        # type (mime type)\n",
    "        return Response(generate(),\n",
    "                        mimetype = \"multipart/x-mixed-replace; boundary=frame\")\n",
    "# check to see if this is the main thread of execution\n",
    "        #解析命令行参数和启动Flask应用程序的任务:\n",
    "if __name__ == '__main__':\n",
    "    # construct the argument parser and parse command line arguments\n",
    "    #ap = argparse.ArgumentParser()\n",
    "    #ap.add_argument(\"-i\", \"--ip\", type=str, required=True,\n",
    "    #                help=\"ip address of the device\")#您运行webstream.py文件的系统的IP地址。\n",
    "    #ap.add_argument(\"-o\", \"--port\", type=int, required=True,# Flask应用程序的运行端口号(对这个参数，您通常只需要提供一个值8000）\n",
    "    #                help=\"ephemeral port number of the server (1024 to 65535)\")\n",
    "    #ap.add_argument(\"-f\", \"--frame-count\", type=int, default=32,#在执行运动检测之前用于累计和构建背景模型的帧数。默认情况下，我们使用32帧来构建背景模型。 \n",
    "    #                help=\"# of frames used to construct the background model\")\n",
    "    #args = vars(ap.parse_args())#函数返回对象object的属性和属性值的字典对象\n",
    "    args = {'ip':'192.168.3.3','port':8000,'frame_count':32}\n",
    "    #启动一个线程用于执行运动检测。\n",
    "    #使用一个线程确保detect_motion函数可以安全地在后台运行——它将不断地运行和更新我们的outputFrame，以便我们可以为我们的客户端提供任何运动检测结果\n",
    "    # start a thread that will perform motion detection\n",
    "    t = threading.Thread(target=detect_motion, args=(\n",
    "        args[\"frame_count\"],))\n",
    "    t.daemon = True\n",
    "    t.start()\n",
    "    # start the flask app#134和135行启动Flask应用程序本身。\n",
    "    app.run(host=args[\"ip\"], port=args[\"port\"], debug=True,\n",
    "            threaded=True, use_reloader=False)\n",
    "# release the video stream pointer\n",
    "vs.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
